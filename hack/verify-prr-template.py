#!/usr/bin/env python3

"""
Verify that KEPs have all required Production Readiness Review (PRR) sections and questions.

This script validates that all KEPs contain the complete Production Readiness Review
Questionnaire with all required subsections and questions as defined in the KEP template.

For existing KEPs that don't meet the requirements, they are tracked in a baseline file
(hack/prr-baseline.txt). Only NEW KEPs that fail validation will cause this script to fail.
This allows us to enforce the standard going forward while grandfathering existing KEPs.
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Set

# Define the expected PRR structure
# Each subsection contains a list of required question patterns (first few words to match)
PRR_STRUCTURE = {
    "Feature Enablement and Rollback": [
        "How can this feature be enabled / disabled",
        "Does enabling the feature change any default behavior",
        "Can the feature be disabled once it has been enabled",
        "What happens if we reenable the feature",
        "Are there any tests for feature enablement/disablement",
    ],
    "Rollout, Upgrade and Rollback Planning": [
        "How can a rollout or rollback fail",
        "What specific metrics should inform a rollback",
        "Were upgrade and rollback tested",
        "Is the rollout accompanied by any deprecations",
    ],
    "Monitoring Requirements": [
        "How can an operator determine if the feature is in use",
        "How can someone using this feature know that it is working",
        "What are the reasonable SLOs",
        "What are the SLIs",
        "Are there any missing metrics",
    ],
    "Dependencies": [
        "Does this feature depend on any specific services",
    ],
    "Scalability": [
        "Will enabling / using this feature result in any new API calls",
        "Will enabling / using this feature result in introducing new API types",
        "Will enabling / using this feature result in any new calls to the cloud provider",
        "Will enabling / using this feature result in increasing size or count",
        "Will enabling / using this feature result in increasing time taken",
        "Will enabling / using this feature result in non-negligible increase of resource usage",
        "Can enabling / using this feature result in resource exhaustion",
    ],
    "Troubleshooting": [
        "How does this feature react if the API server",
        "What are other known failure modes",
        "What steps should be taken if SLOs are not being met",
    ],
}


class KEPValidator:
    def __init__(self, keps_dir: Path, baseline_file: Path):
        self.keps_dir = keps_dir
        self.baseline_file = baseline_file
        self.failed_keps = []
        self.passed_keps = []
        self.skipped_keps = []
        self.grandfathered_keps = []  # KEPs that fail but are in baseline
        self.new_failures = []  # KEPs that fail and are NOT in baseline
        self.baseline = self.load_baseline()

    def load_baseline(self) -> Set[str]:
        """
        Load the baseline file containing KEPs that are allowed to fail validation.

        Returns:
            Set of relative KEP paths that are in the baseline
        """
        if not self.baseline_file.exists():
            return set()

        try:
            with open(self.baseline_file, 'r') as f:
                # Read lines, strip whitespace, and ignore empty lines and comments
                return {
                    line.strip()
                    for line in f
                    if line.strip() and not line.strip().startswith('#')
                }
        except Exception as e:
            print(f"Warning: Failed to read baseline file: {e}")
            return set()

    def save_baseline(self, failed_kep_paths: List[str]) -> None:
        """
        Save the baseline file with the current list of failing KEPs.

        Args:
            failed_kep_paths: List of relative KEP paths that are failing validation
        """
        try:
            with open(self.baseline_file, 'w') as f:
                f.write("# This file contains KEPs that are allowed to fail PRR validation\n")
                f.write("# These are existing KEPs that were created before the requirement was enforced\n")
                f.write("# New KEPs must pass validation - do not add new entries to this file manually\n")
                f.write("#\n")
                f.write("# This file is auto-generated by hack/verify-prr-template.py\n")
                f.write("#\n\n")
                for kep_path in sorted(failed_kep_paths):
                    f.write(f"{kep_path}\n")
            print(f"\nBaseline file created: {self.baseline_file}")
            print(f"Added {len(failed_kep_paths)} KEPs to baseline")
        except Exception as e:
            print(f"Error: Failed to write baseline file: {e}")
            sys.exit(1)

    def find_all_keps(self) -> List[Path]:
        """Find all KEP README.md files in the repository."""
        kep_files = []

        # Find all sig-* directories
        for sig_dir in self.keps_dir.glob("sig-*"):
            if not sig_dir.is_dir():
                continue

            # Find all KEP directories (matching pattern NNNN-*)
            for kep_dir in sig_dir.glob("*"):
                if not kep_dir.is_dir():
                    continue

                readme = kep_dir / "README.md"
                if readme.exists():
                    kep_files.append(readme)

        # Also check for KEPs directly in keps/ directory
        for kep_dir in self.keps_dir.glob("*"):
            if not kep_dir.is_dir() or kep_dir.name.startswith("sig-"):
                continue

            readme = kep_dir / "README.md"
            if readme.exists():
                kep_files.append(readme)

        return sorted(kep_files)

    def parse_markdown_headings(self, content: str) -> List[Tuple[int, str, int]]:
        """
        Parse markdown headings from content.

        Returns:
            List of tuples (level, text, line_number)
        """
        headings = []
        lines = content.split('\n')

        for line_num, line in enumerate(lines, 1):
            # Match ATX-style headings (## Heading)
            match = re.match(r'^(#{1,6})\s+(.+?)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                headings.append((level, text, line_num))

        return headings

    def find_prr_section(self, headings: List[Tuple[int, str, int]]) -> Tuple[int, int]:
        """
        Find the start and end indices of the PRR section in the headings list.

        Returns:
            Tuple of (start_index, end_index) or (-1, -1) if not found
        """
        start_idx = -1
        end_idx = -1

        for idx, (level, text, _) in enumerate(headings):
            # Look for the PRR section (level 2 heading)
            if level == 2 and "Production Readiness Review Questionnaire" in text:
                start_idx = idx

                # Find the end of this section (next level 2 heading)
                for end_idx in range(idx + 1, len(headings)):
                    if headings[end_idx][0] <= 2:
                        return (start_idx, end_idx)

                # If no next level 2 heading found, PRR section extends to end
                return (start_idx, len(headings))

        return (-1, -1)

    def validate_prr_structure(self, headings: List[Tuple[int, str, int]],
                               start_idx: int, end_idx: int) -> Tuple[bool, List[str]]:
        """
        Validate that all required PRR subsections and questions are present.

        Returns:
            Tuple of (is_valid, list_of_errors)
        """
        errors = []
        prr_headings = headings[start_idx:end_idx]

        # Track which subsections and questions we've found
        found_subsections = set()
        found_questions = {subsection: set() for subsection in PRR_STRUCTURE.keys()}

        current_subsection = None

        for level, text, line_num in prr_headings[1:]:  # Skip the PRR heading itself
            # Level 3 headings are subsections
            if level == 3:
                # Check if this matches any expected subsection
                for subsection in PRR_STRUCTURE.keys():
                    if subsection.lower() in text.lower():
                        current_subsection = subsection
                        found_subsections.add(subsection)
                        break

            # Level 6 headings are questions
            elif level == 6 and current_subsection:
                # Check if this matches any expected question in the current subsection
                for question_pattern in PRR_STRUCTURE[current_subsection]:
                    if question_pattern.lower() in text.lower():
                        found_questions[current_subsection].add(question_pattern)
                        break

        # Check for missing subsections
        for subsection in PRR_STRUCTURE.keys():
            if subsection not in found_subsections:
                errors.append(f"Missing subsection: '{subsection}'")

        # Check for missing questions in each subsection
        for subsection, questions in PRR_STRUCTURE.items():
            if subsection in found_subsections:
                for question_pattern in questions:
                    if question_pattern not in found_questions[subsection]:
                        errors.append(f"Missing question in '{subsection}': '{question_pattern}...'")

        return (len(errors) == 0, errors)

    def validate_kep(self, kep_path: Path) -> Tuple[bool, List[str]]:
        """
        Validate a single KEP file.

        Returns:
            Tuple of (is_valid, list_of_errors)
        """
        errors = []

        # Read the KEP file
        try:
            content = kep_path.read_text(encoding='utf-8')
        except Exception as e:
            return (False, [f"Failed to read file: {e}"])

        # Parse headings
        headings = self.parse_markdown_headings(content)

        if not headings:
            return (False, ["No headings found in file"])

        # Find PRR section
        start_idx, end_idx = self.find_prr_section(headings)

        if start_idx == -1:
            return (False, ["Production Readiness Review Questionnaire section not found"])

        # Validate PRR structure
        is_valid, prr_errors = self.validate_prr_structure(headings, start_idx, end_idx)

        return (is_valid, prr_errors)

    def should_skip_kep(self, kep_path: Path) -> Tuple[bool, str]:
        """
        Determine if a KEP should be skipped from validation.

        Returns:
            Tuple of (should_skip, reason)
        """
        # Skip the template KEP
        if "kep-template" in str(kep_path).lower():
            return (True, "template KEP")

        # Skip prod-readiness directory (not a KEP, just documentation)
        if "prod-readiness" in str(kep_path):
            return (True, "not a KEP")

        return (False, "")

    def validate_all(self) -> int:
        """
        Validate all KEPs in the repository.

        Returns:
            Exit code (0 for success, 1 for new failures)
        """
        kep_files = self.find_all_keps()

        if not kep_files:
            print("No KEP files found!")
            return 1

        # Check if baseline exists, if not we'll need to create it
        baseline_exists = self.baseline_file.exists()

        if not baseline_exists:
            print(f"Baseline file not found at {self.baseline_file}")
            print("Creating baseline from current failures...\n")

        print(f"Found {len(kep_files)} KEP files to validate\n")

        for kep_path in kep_files:
            # Check if we should skip this KEP
            should_skip, skip_reason = self.should_skip_kep(kep_path)
            if should_skip:
                self.skipped_keps.append((kep_path, skip_reason))
                continue

            # Get relative path for display and baseline comparison
            try:
                rel_path = kep_path.relative_to(self.keps_dir.parent)
            except ValueError:
                rel_path = kep_path

            rel_path_str = str(rel_path)

            # Validate the KEP
            is_valid, errors = self.validate_kep(kep_path)

            if is_valid:
                self.passed_keps.append(kep_path)
                print(f"✓ {rel_path}")
            else:
                # Check if this failure is in the baseline (grandfathered)
                if rel_path_str in self.baseline:
                    self.grandfathered_keps.append((kep_path, errors))
                    print(f"⊗ {rel_path} (grandfathered)")
                else:
                    self.new_failures.append((kep_path, errors))
                    self.failed_keps.append((kep_path, errors))
                    print(f"✗ {rel_path} (NEW FAILURE)")
                    for error in errors:
                        print(f"  - {error}")
                    print()

        # If baseline doesn't exist, create it with all current failures
        if not baseline_exists:
            all_failing_paths = []
            for kep_path, _ in self.grandfathered_keps + self.new_failures:
                try:
                    rel_path = kep_path.relative_to(self.keps_dir.parent)
                    all_failing_paths.append(str(rel_path))
                except ValueError:
                    all_failing_paths.append(str(kep_path))

            if all_failing_paths:
                self.save_baseline(all_failing_paths)

        # Print summary
        print("\n" + "=" * 80)
        print("SUMMARY")
        print("=" * 80)
        print(f"Total KEPs found:    {len(kep_files)}")
        print(f"Skipped:             {len(self.skipped_keps)}")
        print(f"Validated:           {len(self.passed_keps) + len(self.grandfathered_keps) + len(self.new_failures)}")
        print(f"Passed:              {len(self.passed_keps)}")
        print(f"Grandfathered:       {len(self.grandfathered_keps)} (existing KEPs allowed to fail)")
        print(f"New Failures:        {len(self.new_failures)} (NEW KEPs that must be fixed)")

        if self.new_failures:
            print("\n" + "=" * 80)
            print("NEW FAILURES (Must be fixed!)")
            print("=" * 80)
            for kep_path, errors in self.new_failures:
                try:
                    rel_path = kep_path.relative_to(self.keps_dir.parent)
                except ValueError:
                    rel_path = kep_path
                print(f"\n{rel_path}:")
                for error in errors:
                    print(f"  - {error}")

        # Return exit code - only fail if there are NEW failures
        if self.new_failures:
            print("\n" + "=" * 80)
            print("VALIDATION FAILED: New KEPs must have complete PRR sections")
            print("=" * 80)
            return 1

        print("\n" + "=" * 80)
        print("VALIDATION PASSED: No new KEPs with missing PRR sections")
        print("=" * 80)
        return 0


def main():
    """Main entry point."""
    # Find the keps directory
    script_dir = Path(__file__).parent.parent
    keps_dir = script_dir / "keps"
    baseline_file = script_dir / "hack" / "prr-baseline.txt"

    if not keps_dir.exists():
        print(f"Error: KEPs directory not found at {keps_dir}")
        return 1

    validator = KEPValidator(keps_dir, baseline_file)
    return validator.validate_all()


if __name__ == "__main__":
    sys.exit(main())
